/*
 * DPDK NUMA Architecture Demonstration
 * Lesson 15: NUMA Basics
 *
 * This example demonstrates:
 * 1. Querying NUMA topology information
 * 2. Getting lcore and device socket IDs
 * 3. Creating resources on specific NUMA nodes
 * 4. Demonstrating local vs remote memory access patterns
 * 5. Performance comparison between local and cross-NUMA access
 */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <inttypes.h>
#include <signal.h>
#include <unistd.h>

#include <rte_eal.h>
#include <rte_lcore.h>
#include <rte_ring.h>
#include <rte_mempool.h>
#include <rte_mbuf.h>
#include <rte_ethdev.h>
#include <rte_cycles.h>
#include <rte_malloc.h>

#define RING_SIZE 1024
#define NUM_MBUFS 8191
#define MBUF_CACHE_SIZE 250
#define TEST_ITERATIONS 1000000
#define BATCH_SIZE 32

/* å…¨å±€æ ‡å¿—,ç”¨äºä¼˜é›…é€€å‡º */
static volatile int force_quit = 0;

/* æ€§èƒ½æµ‹è¯•ç»“æœ */
struct perf_stats {
    uint64_t local_cycles;      // æœ¬åœ°NUMAè®¿é—®è€—æ—¶
    uint64_t remote_cycles;     // è·¨NUMAè®¿é—®è€—æ—¶
    uint64_t iterations;        // æµ‹è¯•è¿­ä»£æ¬¡æ•°
};

/* ä¿¡å·å¤„ç†å‡½æ•° */
static void signal_handler(int signum) {
    if (signum == SIGINT || signum == SIGTERM) {
        printf("\n\nSignal %d received, preparing to exit...\n", signum);
        force_quit = 1;
    }
}

/*
 * æ‰“å°NUMAæ‹“æ‰‘ä¿¡æ¯
 * æ˜¾ç¤ºç³»ç»Ÿä¸­æ‰€æœ‰NUMAèŠ‚ç‚¹å’Œæ¯ä¸ªlcoreçš„NUMAå½’å±
 */
static void print_numa_topology(void) {
    unsigned lcore_id;
    unsigned socket_id;
    unsigned num_sockets = 0;
    unsigned socket_lcores[RTE_MAX_NUMA_NODES] = {0};

    printf("\n=== NUMA Topology Information ===\n");

    /* ç»Ÿè®¡NUMAèŠ‚ç‚¹æ•°é‡ */
    RTE_LCORE_FOREACH(lcore_id) {
        socket_id = rte_lcore_to_socket_id(lcore_id);
        if (socket_id + 1 > num_sockets)
            num_sockets = socket_id + 1;
        socket_lcores[socket_id]++;
    }

    printf("Total NUMA nodes: %u\n\n", num_sockets);

    /* æ‰“å°æ¯ä¸ªNUMAèŠ‚ç‚¹çš„lcoreä¿¡æ¯ */
    for (socket_id = 0; socket_id < num_sockets; socket_id++) {
        printf("NUMA Node %u:\n", socket_id);
        printf("  Lcores: ");

        RTE_LCORE_FOREACH(lcore_id) {
            if (rte_lcore_to_socket_id(lcore_id) == socket_id) {
                printf("%u ", lcore_id);
            }
        }
        printf("\n");
        printf("  Total: %u lcores\n\n", socket_lcores[socket_id]);
    }
}

/*
 * æ‰“å°ç½‘å¡çš„NUMAä¿¡æ¯
 * æ˜¾ç¤ºæ¯ä¸ªç½‘å¡ä½äºå“ªä¸ªNUMAèŠ‚ç‚¹
 */
static void print_port_numa_info(void) {
    uint16_t port_id;
    int socket_id;
    uint16_t nb_ports = rte_eth_dev_count_avail();

    if (nb_ports == 0) {
        printf("=== Network Ports ===\n");
        printf("No Ethernet ports available (use --no-pci for demo)\n\n");
        return;
    }

    printf("=== Network Ports NUMA Information ===\n");

    RTE_ETH_FOREACH_DEV(port_id) {
        socket_id = rte_eth_dev_socket_id(port_id);

        if (socket_id == SOCKET_ID_ANY) {
            printf("Port %u: SOCKET_ID_ANY (virtual device or single NUMA)\n",
                   port_id);
        } else {
            printf("Port %u: NUMA Node %d\n", port_id, socket_id);
        }
    }
    printf("\n");
}

/*
 * åœ¨æŒ‡å®šNUMAèŠ‚ç‚¹åˆ›å»ºæµ‹è¯•èµ„æº
 * è¿”å›: æˆåŠŸè¿”å›mempoolæŒ‡é’ˆ,å¤±è´¥è¿”å›NULL
 */
static struct rte_mempool* create_numa_resources(unsigned socket_id,
                                                  struct rte_ring **ring) {
    char pool_name[RTE_MEMPOOL_NAMESIZE];
    char ring_name[RTE_RING_NAMESIZE];
    struct rte_mempool *mbuf_pool;

    /* åˆ›å»ºå¸¦socketæ ‡è¯†çš„åç§° */
    snprintf(pool_name, sizeof(pool_name), "mbuf_pool_socket%u", socket_id);
    snprintf(ring_name, sizeof(ring_name), "ring_socket%u", socket_id);

    printf("Creating resources on NUMA Node %u...\n", socket_id);

    /* åœ¨æŒ‡å®šNUMAèŠ‚ç‚¹åˆ›å»ºmbuf pool */
    mbuf_pool = rte_pktmbuf_pool_create(
        pool_name,
        NUM_MBUFS,
        MBUF_CACHE_SIZE,
        0,
        RTE_MBUF_DEFAULT_BUF_SIZE,
        socket_id  /* å…³é”®: æŒ‡å®šNUMAèŠ‚ç‚¹ */
    );

    if (mbuf_pool == NULL) {
        rte_exit(EXIT_FAILURE,
                 "Cannot create mbuf pool on socket %u: %s\n",
                 socket_id, rte_strerror(rte_errno));
    }

    printf("  âœ“ Mbuf pool '%s' created on NUMA %u\n", pool_name, socket_id);

    /* åœ¨æŒ‡å®šNUMAèŠ‚ç‚¹åˆ›å»ºring */
    *ring = rte_ring_create(
        ring_name,
        RING_SIZE,
        socket_id,  /* å…³é”®: æŒ‡å®šNUMAèŠ‚ç‚¹ */
        RING_F_SP_ENQ | RING_F_SC_DEQ
    );

    if (*ring == NULL) {
        rte_exit(EXIT_FAILURE,
                 "Cannot create ring on socket %u: %s\n",
                 socket_id, rte_strerror(rte_errno));
    }

    printf("  âœ“ Ring '%s' created on NUMA %u\n", ring_name, socket_id);

    return mbuf_pool;
}

/*
 * æ€§èƒ½æµ‹è¯•: æœ¬åœ°NUMAè®¿é—®
 * æµ‹è¯•åœ¨åŒä¸€NUMAèŠ‚ç‚¹ä¸Šåˆ†é…å’Œè®¿é—®å†…å­˜çš„æ€§èƒ½
 */
static uint64_t test_local_numa_access(struct rte_mempool *mbuf_pool,
                                         unsigned iterations) {
    struct rte_mbuf *mbufs[BATCH_SIZE];
    uint64_t start_cycles, end_cycles;
    unsigned i, j;

    start_cycles = rte_rdtsc();

    for (i = 0; i < iterations / BATCH_SIZE; i++) {
        /* ä»æœ¬åœ°NUMAçš„mempoolåˆ†é…mbuf */
        if (rte_pktmbuf_alloc_bulk(mbuf_pool, mbufs, BATCH_SIZE) != 0) {
            printf("Failed to allocate mbufs\n");
            return 0;
        }

        /* æ¨¡æ‹Ÿæ•°æ®è®¿é—® - å†™å…¥æ•°æ® */
        for (j = 0; j < BATCH_SIZE; j++) {
            char *data = rte_pktmbuf_mtod(mbufs[j], char *);
            memset(data, 0xAA, 64);  /* å†™å…¥64å­—èŠ‚ */
        }

        /* é‡Šæ”¾mbufå›pool */
        for (j = 0; j < BATCH_SIZE; j++) {
            rte_pktmbuf_free(mbufs[j]);
        }
    }

    end_cycles = rte_rdtsc();
    return end_cycles - start_cycles;
}

/*
 * æ€§èƒ½æµ‹è¯•: è·¨NUMAè®¿é—®
 * æµ‹è¯•ä»å¦ä¸€ä¸ªNUMAèŠ‚ç‚¹çš„å†…å­˜æ± åˆ†é…å’Œè®¿é—®çš„æ€§èƒ½
 */
static uint64_t test_remote_numa_access(struct rte_mempool *remote_pool,
                                          unsigned iterations) {
    struct rte_mbuf *mbufs[BATCH_SIZE];
    uint64_t start_cycles, end_cycles;
    unsigned i, j;

    start_cycles = rte_rdtsc();

    for (i = 0; i < iterations / BATCH_SIZE; i++) {
        /* ä»è¿œç¨‹NUMAçš„mempoolåˆ†é…mbuf */
        if (rte_pktmbuf_alloc_bulk(remote_pool, mbufs, BATCH_SIZE) != 0) {
            printf("Failed to allocate mbufs\n");
            return 0;
        }

        /* æ¨¡æ‹Ÿæ•°æ®è®¿é—® - è·¨NUMAè®¿é—®å†…å­˜ */
        for (j = 0; j < BATCH_SIZE; j++) {
            char *data = rte_pktmbuf_mtod(mbufs[j], char *);
            memset(data, 0xBB, 64);  /* è·¨NUMAå†™å…¥ */
        }

        /* é‡Šæ”¾mbufå›pool */
        for (j = 0; j < BATCH_SIZE; j++) {
            rte_pktmbuf_free(mbufs[j]);
        }
    }

    end_cycles = rte_rdtsc();
    return end_cycles - start_cycles;
}

/*
 * è¿è¡ŒNUMAæ€§èƒ½å¯¹æ¯”æµ‹è¯•
 */
static void run_numa_performance_test(void) {
    unsigned current_socket = rte_socket_id();
    unsigned remote_socket;
    struct rte_mempool *local_pool, *remote_pool;
    struct rte_ring *local_ring, *remote_ring;
    struct perf_stats stats;
    uint64_t hz = rte_get_timer_hz();

    printf("\n=== NUMA Performance Test ===\n");
    printf("Current lcore %u running on NUMA Node %u\n",
           rte_lcore_id(), current_socket);

    /* ç¡®å®šè¿œç¨‹NUMAèŠ‚ç‚¹ */
    if (rte_socket_count() < 2) {
        printf("âš  Warning: System has only %u NUMA node(s)\n",
               rte_socket_count());
        printf("Cross-NUMA test will use same node (no performance difference expected)\n");
        remote_socket = current_socket;
    } else {
        remote_socket = (current_socket == 0) ? 1 : 0;
        printf("Using NUMA Node %u as remote node for comparison\n\n",
               remote_socket);
    }

    /* åˆ›å»ºæœ¬åœ°å’Œè¿œç¨‹èµ„æº */
    local_pool = create_numa_resources(current_socket, &local_ring);
    remote_pool = create_numa_resources(remote_socket, &remote_ring);

    printf("\n--- Running Performance Tests ---\n");
    printf("Testing %u iterations with batch size %u...\n\n",
           TEST_ITERATIONS, BATCH_SIZE);

    /* æµ‹è¯•æœ¬åœ°NUMAè®¿é—® */
    printf("Test 1: Local NUMA access (Node %u â†’ Node %u)...\n",
           current_socket, current_socket);
    stats.local_cycles = test_local_numa_access(local_pool, TEST_ITERATIONS);

    /* æµ‹è¯•è·¨NUMAè®¿é—® */
    printf("Test 2: Remote NUMA access (Node %u â†’ Node %u)...\n",
           current_socket, remote_socket);
    stats.remote_cycles = test_remote_numa_access(remote_pool, TEST_ITERATIONS);

    stats.iterations = TEST_ITERATIONS;

    /* æ‰“å°ç»“æœ */
    printf("\n=== Performance Results ===\n");
    printf("Test iterations: %"PRIu64"\n", stats.iterations);
    printf("Batch size: %u\n\n", BATCH_SIZE);

    printf("Local NUMA access:\n");
    printf("  Total cycles: %"PRIu64"\n", stats.local_cycles);
    printf("  Cycles per op: %"PRIu64"\n",
           stats.local_cycles / stats.iterations);
    printf("  Time: %.3f ms\n",
           (double)stats.local_cycles * 1000.0 / hz);

    printf("\nRemote NUMA access:\n");
    printf("  Total cycles: %"PRIu64"\n", stats.remote_cycles);
    printf("  Cycles per op: %"PRIu64"\n",
           stats.remote_cycles / stats.iterations);
    printf("  Time: %.3f ms\n",
           (double)stats.remote_cycles * 1000.0 / hz);

    if (stats.local_cycles > 0) {
        double overhead = ((double)stats.remote_cycles / stats.local_cycles - 1.0) * 100.0;
        printf("\nğŸ“Š Performance Impact:\n");
        printf("  Remote access overhead: %.1f%%\n", overhead);

        if (overhead > 5.0 && remote_socket != current_socket) {
            printf("  âš  Significant cross-NUMA penalty detected!\n");
        } else if (remote_socket == current_socket) {
            printf("  â„¹ Single NUMA system - no cross-NUMA penalty expected\n");
        } else {
            printf("  âœ“ Low cross-NUMA penalty (good cache locality)\n");
        }
    }
}

/*
 * æ¼”ç¤ºæ­£ç¡®å’Œé”™è¯¯çš„NUMAç”¨æ³•
 */
static void demonstrate_numa_best_practices(void) {
    unsigned current_socket = rte_socket_id();
    unsigned wrong_socket = (current_socket == 0) ? 1 : 0;

    printf("\n=== NUMA Best Practices ===\n\n");

    printf("âœ… CORRECT: Create resources on local NUMA node\n");
    printf("   unsigned socket_id = rte_socket_id();  // Get current socket\n");
    printf("   struct rte_ring *ring = rte_ring_create(\n");
    printf("       \"my_ring\", 1024, socket_id, 0);  // â† Use local socket\n");
    printf("   Current socket: %u âœ“\n\n", current_socket);

    printf("âŒ WRONG: Create on wrong NUMA node\n");
    printf("   struct rte_ring *ring = rte_ring_create(\n");
    printf("       \"my_ring\", 1024, %u, 0);  // â† Wrong socket!\n", wrong_socket);
    printf("   This causes cross-NUMA access penalty\n\n");

    printf("âœ… CORRECT: Bind mempool to NIC socket\n");
    printf("   uint16_t port_id = 0;\n");
    printf("   int port_socket = rte_eth_dev_socket_id(port_id);\n");
    printf("   struct rte_mempool *pool = rte_pktmbuf_pool_create(\n");
    printf("       \"mbuf_pool\", 8192, 250, 0, 2048, port_socket);\n\n");

    printf("âŒ WRONG: Use SOCKET_ID_ANY (unpredictable)\n");
    printf("   struct rte_mempool *pool = rte_pktmbuf_pool_create(\n");
    printf("       \"mbuf_pool\", 8192, 250, 0, 2048, SOCKET_ID_ANY);\n");
    printf("   Don't rely on system to choose!\n\n");

    printf("ğŸ’¡ Pro Tips:\n");
    printf("   1. Use 'numactl --hardware' to check system topology\n");
    printf("   2. Use 'cat /sys/class/net/ethX/device/numa_node' for NIC location\n");
    printf("   3. Launch app with: --socket-mem=1024,0 to limit memory per node\n");
    printf("   4. Use 'numastat -p <pid>' to monitor NUMA memory usage\n");
}

/*
 * ä¸»å‡½æ•°
 */
int main(int argc, char **argv) {
    int ret;
    unsigned lcore_id;

    /* æ³¨å†Œä¿¡å·å¤„ç† */
    signal(SIGINT, signal_handler);
    signal(SIGTERM, signal_handler);

    /* åˆå§‹åŒ–EAL */
    ret = rte_eal_init(argc, argv);
    if (ret < 0)
        rte_panic("Cannot init EAL\n");

    /* æ‰“å°æ¬¢è¿ä¿¡æ¯ */
    printf("\n");
    printf("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n");
    printf("â•‘   DPDK NUMA Architecture Demonstration - Lesson 15    â•‘\n");
    printf("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    /* æ£€æŸ¥lcoreæ•°é‡ */
    if (rte_lcore_count() < 1) {
        rte_exit(EXIT_FAILURE, "Need at least 1 lcore\n");
    }

    lcore_id = rte_lcore_id();
    printf("Running on lcore %u (NUMA Node %u)\n",
           lcore_id, rte_socket_id());
    printf("Total system NUMA nodes: %u\n", rte_socket_count());
    printf("Total available lcores: %u\n", rte_lcore_count());

    /* 1. æ‰“å°NUMAæ‹“æ‰‘ */
    print_numa_topology();

    /* 2. æ‰“å°ç½‘å¡NUMAä¿¡æ¯ */
    print_port_numa_info();

    /* 3. æ¼”ç¤ºæœ€ä½³å®è·µ */
    demonstrate_numa_best_practices();

    /* 4. è¿è¡Œæ€§èƒ½æµ‹è¯• */
    if (!force_quit) {
        run_numa_performance_test();
    }

    /* æ€»ç»“ */
    printf("\n=== Summary ===\n");
    printf("Key takeaways:\n");
    printf("  1. Always check NUMA topology with rte_socket_id()\n");
    printf("  2. Create resources on the same NUMA node as the worker lcore\n");
    printf("  3. Bind mempool to the same NUMA node as the NIC\n");
    printf("  4. Cross-NUMA access can cause 30-50%% performance penalty\n");
    printf("  5. Use numactl and numastat for monitoring\n");

    printf("\nğŸ“š For multi-NUMA systems, run with:\n");
    printf("   sudo ./numa_demo -l 0-3 --socket-mem=1024,1024\n");
    printf("   (Allocates memory on both NUMA nodes)\n");

    /* æ¸…ç†EAL */
    rte_eal_cleanup();

    printf("\nProgram exited cleanly.\n");
    return 0;
}
